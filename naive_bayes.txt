words, labels = load_file(training_file)
    training_dic = dict(zip(words, labels))

    words, labels = load_file(development_file)
    development_dic = dict(zip(words, labels))

    features_matrix = np.zeros((len(training_dic), 2))
    lab_vec = np.zeros(len(training_dic))
    i = 0
    for word in training_dic.keys():
        features_matrix[i, 0] = len(word)
        count = counts[word]
        if count == 0:
            fixed_word = re.sub(pattern="-", repl="", string = word)
            count = counts[fixed_word]
        features_matrix[i, 1] = count
        lab_vec[i] = training_dic[word]
        i += 1
    features_matrix[ :, 0] = norm(features_matrix[ :, 0])
    features_matrix[ :, 1] = norm(features_matrix[ :, 1])

    dev_matrix = np.zeros((len(development_dic), 2))
    dev_vec = np.zeros(len(development_dic))

    i = 0
    for word in development_dic.keys():
        dev_matrix[i, 0] = len(word)
        count = counts[word]
        if count == 0:
            fixed_word = re.sub(pattern="-", repl="", string = word)
            count = counts[fixed_word]
        dev_matrix[i, 1] = count
        dev_vec[i] = development_dic[word]
        i += 1
    dev_matrix[ :, 0] = norm(dev_matrix[ :, 0])
    dev_matrix[ :, 1] = norm(dev_matrix[ :, 1])

    clf.fit(features_matrix, lab_vec)
    
    train_pred = clf.predict(features_matrix)
    dev_pred = clf.predict(dev_matrix)

    tprecision = get_precision(train_pred, lab_vec)
    trecall = get_recall(train_pred, lab_vec)
    tfscore = get_fscore(train_pred, lab_vec)

    dprecision = get_precision(dev_pred, dev_vec)
    dfscore = get_fscore(dev_pred, dev_vec)
    drecall = get_recall(dev_pred, dev_vec)

    print("Naive Bayes Performance Statistics")
    test_predictions(dev_pred, dev_vec)
    print("Training F-Score: " + str(tfscore))

    training_performance = [tprecision, trecall, tfscore]
    development_performance = [dprecision, drecall, dfscore]
    return training_performance, development_performance